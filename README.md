# Week 9: Cloud-Hosted Notebook Data Manipulation

In addition to Google Colab, there are several other cloud-based hosting services that provide environments similar to Jupyter Notebooks. These platforms include Kaggle Kernels, Deepnote, AWS SageMaker, GCP Notebooks, and Azure Notebooks. I have some experience with Kaggle Notebooks, which operate much like Colab. Kaggle Notebooks allow for easy sharing and collaboration, and they offer the convenience of easily accessing Kaggle datasets and competition data.

I also came across a book, "The Kaggle Book," published by O'Reilly, which offers comprehensive information on participating in Kaggle competitions. This book could be a valuable asset for those interested starting a journey on participating competition on Kaggle.
Here is the link to the book: [The Kaggle Book](https://statics.teams.cdn.office.net/evergreen-assets/safelinks/1/atp-safelinks.html)
Additionally, there is an audiobook version available: [The Kaggle Book - Audiobook Version](https://learning.oreilly.com/videos/the-kaggle-book/9781804612361/)


## Kaggle Notebook practice steps:

### Step 1: Browsing the Kaggle Dataset: 
I came across the intriguing [Titanic dataset](https://www.kaggle.com/competitions/titanic/overview), which contains historical records of the passengers on the ill-fated Titanic.

### Step 2: Launching a Kaggle Notebook: 
I initiated a new notebook on Kaggle dedicated to this competition dataset and became familiar with the process of seamlessly loading data from the input folder directly within the Kaggle notebook environment.

### Step 3: Data Manipulation 
* I followed a [comprehensive tutorial](https://www.kaggle.com/code/alexisbcook/titanic-tutorial) and executed code to predict outcomes for the test dataset. 
* During this process, I delved into the Kaggle Notebook's user interface, exploring features such as the data folder, as well as monitoring memory and CPU usage.
* I also gained insights into the Random Forest algorithm employed in the code.
* I successfully conducted data manipulation tasks, achieving the desired results. Additionally, I saved a new CSV file to the output folder.
<img width="396" alt="Screenshot 2023-10-30 at 2 50 59 AM" src="https://github.com/nogibjj/lisa-mini-project-9/assets/46847817/cec11b77-7060-47a6-8a9f-15a5126b8d86">

<img width="396" alt="Screenshot 2023-10-30 at 10 15 24 AM" src="https://github.com/nogibjj/lisa-mini-project-9/assets/46847817/61486290-55c7-407b-92e8-b132a5466896">


### Step 4: Sharing My Work: 
I made my notebook public and obtained a shareable link for others to access and benefit from my work.
Link to [Kaggle Notebook](https://www.kaggle.com/code/lisa0910/titanic/edit)
